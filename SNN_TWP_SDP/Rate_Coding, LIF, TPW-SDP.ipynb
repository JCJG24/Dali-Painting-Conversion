{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f2b6f6",
   "metadata": {},
   "source": [
    "# Import Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b1be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abd2438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import save, load\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a696d0eb",
   "metadata": {},
   "source": [
    "# Define the SNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0906c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on TPW-SDP, Leaky Integrate-and-Fire (LIF) Neurons\n",
    "# Rate Coding for encoding\n",
    "\n",
    "\n",
    "class SNN_TPWSDP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SNN_TPWSDP, self).__init__()\n",
    "        \n",
    "        # Convolutional layers + tpwsdp layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.tpwsdp1 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.tpwsdp2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.tpwsdp3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        # Pooling layers\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.tpwsdp1(x))\n",
    "        \n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.tpwsdp2(x))\n",
    "        \n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.tpwsdp3(x))\n",
    "\n",
    "        # Flatten the output from the convolutional layers\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        #x = x.view(16, -1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TPWSDP(nn.Module):\n",
    "    def __init__(self, beta=0.001):\n",
    "        super(TPWSDP, self).__init__()\n",
    "        self.beta = beta\n",
    "        self.alpha = nn.Parameter(torch.Tensor([0.5]), requires_grad=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if x.dim() == 4:\n",
    "            w = x.mean(dim=(2,3), keepdim=True)\n",
    "        elif x.dim() == 3:\n",
    "            w = x.mean(dim=2, keepdim=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Expected input tensor to have 3 or 4 dimensions, but got {x.dim()} dimensions.\")\n",
    "        w = torch.sigmoid(self.alpha * (w - self.beta))\n",
    "        return x * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7fb355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The SNN consists of three convolutional and three twp-dsp layers, two pooling layers, and two fully connected layers.\n",
    "# The TPW-SDP module is defined separately and is used in the convolutional and fully connected layers...\n",
    "# ...to modify the synaptic weights of the SNN based on the temporal relationship between the spikes in the input and output layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a863d34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used a temporal-precision-weighted spike-dependent plasticity (TPW-SDP) algorithm to train the SNN.\n",
    "# A form of unsupervised learning that adjusts the synaptic weights between neurons based on the temporal precision and timing of the spikes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e027122f",
   "metadata": {},
   "source": [
    "# Define the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb577bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 16         # although better results are extracted when batch_size = 1\n",
    "learning_rate = 1e-3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7133683b",
   "metadata": {},
   "source": [
    "# Load the MNIST dataset and Create a data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73b4943",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='data', download=True, train=True,transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8193d5bd",
   "metadata": {},
   "source": [
    "# Define the Loss Function, Optimizer and Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee3a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrossEntropyLoss applies softmax to the output of the model to convert it into a probability distribution over classes.\n",
    "# Then computes the negative log-likelihood of the true class under this distribution.\n",
    "\n",
    "snn = SNN_TPWSDP().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(snn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f9ee0f",
   "metadata": {},
   "source": [
    "# Training the SNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499792b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skip if you load the pretrained\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for (images, targets) in train_loader:\n",
    "        \n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        outputs = snn(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print ('Epoch [{}/{}], Loss: {}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec90d638",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7fa2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skip if you load the pretrained\n",
    "\n",
    "with open('SNN_TPW-SDP_model_state.pt', 'wb') as f:\n",
    "    save(snn.state_dict(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2502b0",
   "metadata": {},
   "source": [
    "# Load the trained model's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d68bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SNN_TPW-SDP_model_state.pt', 'rb') as f:\n",
    "    snn.load_state_dict(load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d85827",
   "metadata": {},
   "source": [
    "# Test an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05527162",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"Filepath to image\\\\img_3.jpg\")\n",
    "img_tensor = transforms.ToTensor()(img).unsqueeze(0).to(device)\n",
    "\n",
    "print(torch.argmax(snn(img_tensor)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptod",
   "language": "python",
   "name": "ptod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
