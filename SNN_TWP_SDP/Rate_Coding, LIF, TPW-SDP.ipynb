{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f2b6f6",
   "metadata": {},
   "source": [
    "# Import Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b1be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abd2438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import save, load\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd.function import Function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a696d0eb",
   "metadata": {},
   "source": [
    "# Define the SNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fa0107",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIFNeuron(nn.Module):\n",
    "    def __init__(self, threshold=1.0, reset=0.0):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "        self.reset = reset\n",
    "\n",
    "    def forward(self, x, dt=1.0):\n",
    "        batch_size, channels, width, height = x.size()\n",
    "        x = x.view(batch_size, channels, width * height)\n",
    "\n",
    "        # Initialize membrane potential and output spike\n",
    "        v = torch.zeros_like(x)\n",
    "        spike = torch.zeros_like(x)\n",
    "\n",
    "        # Update membrane potential and output spike iteratively\n",
    "        for t in range(int(dt)):\n",
    "            dv = (x - v) / self.threshold\n",
    "            v += dv\n",
    "            spk = (v >= 1.0).float()\n",
    "            spike += spk\n",
    "            v -= spk * (self.threshold - self.reset)\n",
    "\n",
    "        # Update membrane potential with remaining input\n",
    "        dt -= int(dt)\n",
    "        if dt > 0:\n",
    "            dt = torch.tensor(dt).to(x.device)\n",
    "            dv = (x - v) / self.threshold\n",
    "            v += dv * torch.exp(-dt)\n",
    "            spk = (v >= 1.0).float()\n",
    "            spike += spk\n",
    "            v -= spk * (self.threshold - self.reset)\n",
    "\n",
    "        # Reshape spike back to the original size\n",
    "        spike = spike.view(batch_size, channels, width, height)\n",
    "\n",
    "        return spike, v\n",
    "    \n",
    "class LIFLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.neuron = LIFNeuron()\n",
    "\n",
    "    def forward(self, x, dt=1.0):\n",
    "        x = self.conv(x)\n",
    "        x, v = self.neuron(x, dt)\n",
    "        return x\n",
    "\n",
    "class LIFClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LIFClassifier, self).__init__()\n",
    "        self.conv1 = LIFLayer(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.conv2 = LIFLayer(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.conv3 = LIFLayer(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear((64 * 28 // 4) * (28 // 4), 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.pool1(x))\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.pool2(x))\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709e8e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three spiking convolutional layers followed by Two spiking linear layers\n",
    "# Input encoding used in this code: each pixel value representing the intensity of the corresponding pixel in the image\n",
    "\n",
    "# Define a custom spiking activation function\n",
    "class SpikeActivation(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        ctx.save_for_backward(x)\n",
    "        return x.gt(0).float()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[x <= 0] = 0\n",
    "        return grad_input\n",
    "\n",
    "# Define a spiking linear layer\n",
    "class SpikeLinear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(SpikeLinear, self).__init__(in_features, out_features, bias)\n",
    "        self.threshold = nn.Parameter(torch.Tensor([0.5]))\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = F.linear(input, self.weight, self.bias)\n",
    "        return SpikeActivation.apply(output - self.threshold)\n",
    "\n",
    "# Define a spiking convolutional layer\n",
    "class SpikeConv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
    "        super(SpikeConv2d, self).__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias)\n",
    "        self.threshold = nn.Parameter(torch.Tensor([0.5]))\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = F.conv2d(input, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "        return SpikeActivation.apply(output - self.threshold)\n",
    "\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SNN, self).__init__()\n",
    "\n",
    "        # Define convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "        # Define threshold parameter for spiking activation\n",
    "        self.threshold = nn.Parameter(torch.Tensor([0.5]), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutional layers with ReLU activation\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "\n",
    "        # Flatten the output and apply fully connected layers with ReLU activation\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # Apply spiking activation function\n",
    "        x = x - self.threshold\n",
    "        x = x / torch.max(torch.abs(x))\n",
    "        x = torch.sigmoid(100 * (x - 0.2))\n",
    "\n",
    "        return x\n",
    "\n",
    "'''class SNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SNN, self).__init__()\n",
    "\n",
    "        # Spiking convolutional layers\n",
    "        self.conv1 = SpikeConv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        nn.init.kaiming_uniform_(self.conv1.weight, nonlinearity='relu')\n",
    "        self.conv2 = SpikeConv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        nn.init.kaiming_uniform_(self.conv2.weight, nonlinearity='relu')\n",
    "        self.conv3 = SpikeConv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        nn.init.kaiming_uniform_(self.conv3.weight, nonlinearity='relu')\n",
    "\n",
    "        # Spiking linear layers\n",
    "        self.fc1 = SpikeLinear(64 * 7 * 7, 512)\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight, nonlinearity='relu')\n",
    "        self.fc2 = SpikeLinear(512, 10)\n",
    "        nn.init.kaiming_uniform_(self.fc2.weight, nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.poisson(x)\n",
    "        x = self.conv1(x)\n",
    "        x = F.avg_pool2d(x, 2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.avg_pool2d(x, 2)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x'''\n",
    "\n",
    "# Define the spiking neural network\n",
    "'''class SNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SNN, self).__init__()\n",
    "\n",
    "        # Spiking convolutional layers\n",
    "        self.conv1 = SpikeConv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = SpikeConv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = SpikeConv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Spiking linear layers\n",
    "        self.fc1 = SpikeLinear(64 * 7 * 7, 512)\n",
    "        self.fc2 = SpikeLinear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.avg_pool2d(x, 2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.avg_pool2d(x, 2)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0906c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on TPW-SDP, Weight Normalization to simulate Spiking\n",
    "\n",
    "\n",
    "class SNN_TPWSDP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SNN_TPWSDP, self).__init__()\n",
    "        \n",
    "        # Convolutional layers + tpwsdp layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.tpwsdp1 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.tpwsdp2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.tpwsdp3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        # Pooling layers\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.tpwsdp1(x))\n",
    "        \n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.tpwsdp2(x))\n",
    "        \n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.tpwsdp3(x))\n",
    "\n",
    "        # Flatten the output from the convolutional layers\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        #x = x.view(16, -1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TPWSDP(nn.Module):\n",
    "    def __init__(self, beta=0.001):\n",
    "        super(TPWSDP, self).__init__()\n",
    "        self.beta = beta\n",
    "        self.alpha = nn.Parameter(torch.Tensor([0.5]), requires_grad=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if x.dim() == 4:\n",
    "            w = x.mean(dim=(2,3), keepdim=True)\n",
    "        elif x.dim() == 3:\n",
    "            w = x.mean(dim=2, keepdim=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Expected input tensor to have 3 or 4 dimensions, but got {x.dim()} dimensions.\")\n",
    "        w = torch.sigmoid(self.alpha * (w - self.beta))\n",
    "        return x * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7fb355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The S-CNN consists of three convolutional and three twp-dsp layers, two pooling layers, and two fully connected layers.\n",
    "# The TPW-SDP module is defined separately and is used in the convolutional and fully connected layers...\n",
    "# ...to modify the synaptic weights of the SNN based on the temporal relationship between the spikes in the input and output layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a863d34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used a simulation of temporal-precision-weighted spike-dependent plasticity (TPW-SDP) algorithm to train the SNN.\n",
    "# A form of unsupervised learning that adjusts the synaptic weights between neurons based on the temporal precision and timing of the spikes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e027122f",
   "metadata": {},
   "source": [
    "# Define the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb577bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 16         # although better results are extracted when batch_size = 1\n",
    "learning_rate = 1e-3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7133683b",
   "metadata": {},
   "source": [
    "# Load the MNIST dataset and Create a data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73b4943",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='data', download=True, train=True,transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8193d5bd",
   "metadata": {},
   "source": [
    "# Define the Loss Function, Optimizer and Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee3a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrossEntropyLoss applies softmax to the output of the model to convert it into a probability distribution over classes.\n",
    "# Then computes the negative log-likelihood of the true class under this distribution.\n",
    "\n",
    "snn = LIFClassifier().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(snn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f9ee0f",
   "metadata": {},
   "source": [
    "# Training the SNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499792b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Skip if you load the pretrained\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for (images, targets) in train_loader:\n",
    "        \n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        outputs = snn(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print ('Epoch [{}/{}], Loss: {}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec90d638",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7fa2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skip if you load the pretrained\n",
    "\n",
    "with open('SNN.pt', 'wb') as f:\n",
    "    save(snn.state_dict(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2502b0",
   "metadata": {},
   "source": [
    "# Load the trained model's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d68bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SNN.pt', 'rb') as f:\n",
    "    snn.load_state_dict(load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d85827",
   "metadata": {},
   "source": [
    "# Test an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05527162",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"Z:\\\\Jupyter Scripts\\\\PyTorch Object Detection\\\\PTODSNN\\\\Pytorch\\\\data\\\\test\\\\img_3.jpg\")\n",
    "img_tensor = transforms.ToTensor()(img).unsqueeze(0).to(device)\n",
    "\n",
    "print(torch.argmax(snn(img_tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c862ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptod",
   "language": "python",
   "name": "ptod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
